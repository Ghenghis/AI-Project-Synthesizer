# ============================================
# AI Project Synthesizer - Environment Configuration
# ============================================
# Copy this file to .env and fill in your values
# NEVER commit .env to version control!
# ============================================

# ============================================
# APPLICATION SETTINGS
# ============================================
APP_NAME=AI Project Synthesizer
APP_ENV=development
DEBUG=true
LOG_LEVEL=INFO

# ============================================
# SERVER SETTINGS
# ============================================
SERVER_HOST=localhost
SERVER_PORT=8000

# ============================================
# PLATFORM API KEYS (Required: at least GitHub)
# ============================================

# GitHub - Required for repository discovery
# Get token: https://github.com/settings/tokens
# Required scopes: repo (read), read:packages
GITHUB_TOKEN=ghp_your_token_here

# GitLab - Optional
# Get token: https://gitlab.com/-/user_settings/personal_access_tokens
GITLAB_TOKEN=
GITLAB_URL=https://gitlab.com

# HuggingFace - Optional but recommended
# Get token: https://huggingface.co/settings/tokens
HUGGINGFACE_TOKEN=hf_your_token_here

# Kaggle - Optional
# Get credentials: https://www.kaggle.com/account → API → Create New Token
KAGGLE_USERNAME=
KAGGLE_KEY=

# Semantic Scholar - Optional (improves paper search)
# Get key: https://www.semanticscholar.org/product/api
SEMANTIC_SCHOLAR_API_KEY=

# ============================================
# LLM CONFIGURATION
# ============================================

# Ollama - Primary (Local LLM)
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL_FAST=qwen2.5-coder:7b-instruct-q8_0
OLLAMA_MODEL_BALANCED=qwen2.5-coder:14b-instruct-q4_K_M
OLLAMA_MODEL_POWERFUL=qwen2.5-coder:32b-instruct-q4_K_M

# Cloud LLM Fallback - Optional
# Enable with CLOUD_LLM_ENABLED=true
CLOUD_LLM_ENABLED=false

# OpenAI - Optional fallback
# Get key: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your_key_here
OPENAI_MODEL=gpt-4-turbo-preview

# Anthropic - Optional fallback
# Get key: https://console.anthropic.com/
ANTHROPIC_API_KEY=sk-ant-your_key_here
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# ============================================
# ROUTING CONFIGURATION
# ============================================
# Threshold for routing to cloud (0.0-1.0)
# Higher = more local, lower = more cloud
CLOUD_ROUTING_THRESHOLD=0.7

# ============================================
# CACHE CONFIGURATION
# ============================================
CACHE_ENABLED=true
CACHE_TTL_SECONDS=3600
CACHE_DIR=.cache

# Redis (optional, for distributed caching)
REDIS_URL=redis://localhost:6379/0

# ============================================
# OUTPUT CONFIGURATION
# ============================================
DEFAULT_OUTPUT_DIR=./output
TEMP_DIR=./temp

# ============================================
# SYNTHESIS SETTINGS
# ============================================
MAX_REPOS_PER_SYNTHESIS=10
MAX_CONCURRENT_CLONES=3
CLONE_DEPTH=1

# ============================================
# RATE LIMITING
# ============================================
GITHUB_RATE_LIMIT_BUFFER=100
REQUEST_TIMEOUT_SECONDS=30
MAX_RETRIES=3

# ============================================
# LOGGING
# ============================================
LOG_FORMAT=json
LOG_FILE=logs/synthesizer.log
LOG_ROTATION=10MB
LOG_RETENTION=7
